{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('a.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_id': '62695603181473949687510174314055387106', 'category': 'perceptron', 'params': '{\"category\":\"perceptron\",\"model_name\":\"lucua\",\"datasets\":[\"64460f77a4832018aed11964\",\"64460f77a4832018aed119c5\",\"64460f77a4832018aed1190f\",\"64460f77a4832018aed11957\"],\"class_names\":null,\"epoch_num\":10,\"input_dim\":[32,32],\"structure\":[20,20,20],\"activation_name\":\"ReLU\",\"val_percent\":1,\"data_augmentation_config\":null,\"batch_size\":64,\"embedding_dim\":0,\"rnn_units\":0,\"seq_length\":0}', 'datasets': [{'name': 'dreams', 'link': 'https://cdn.generative.xyz/ai-school-dataset/dreams-by-joshua-bagley.zip'}, {'name': 'machine comics', 'link': 'https://cdn.generative.xyz/ai-school-dataset/machine-comics-by-roni-block.zip'}, {'name': 'act of emotion', 'link': 'https://cdn.generative.xyz/ai-school-dataset/act-of-emotion-by-kelly-milligan.zip'}, {'name': 'daisies', 'link': 'https://cdn.generative.xyz/ai-school-dataset/daisies-by-natthakit-susanthitanon-nsmag.zip'}]}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rein = []\n",
    "all = []\n",
    "\n",
    "for user_info in data:\n",
    "    new_user_info = {}\n",
    "    if user_info[\"category\"] == \"perceptron\":\n",
    "        new_user_info = {\n",
    "            \"model_id\": user_info[\"model_id\"],\n",
    "            \"datasets\": []\n",
    "        }\n",
    "        for dataset in user_info[\"datasets\"]:\n",
    "            dataset_url = dataset[\"link\"].replace(\"https://cdn.generative.xyz\", \"https://cdn.eternalai.org\")\n",
    "            new_user_info[\"datasets\"].append(dataset_url)\n",
    "        rein.append((user_info[\"category\"], new_user_info))\n",
    "    else:\n",
    "        new_user_info = {\n",
    "            \"model_id\": user_info[\"model_id\"],\n",
    "            \"datasets\": []\n",
    "        }\n",
    "        for dataset in user_info[\"datasets\"]:\n",
    "            dataset_url = dataset[\"link\"].replace(\"https://cdn.generative.xyz\", \"https://cdn.eternalai.org\")\n",
    "            new_user_info[\"datasets\"].append(dataset_url)\n",
    "        all.append((user_info[\"category\"], new_user_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0.5\n",
    "indices = int(len(all) * 0.5)\n",
    "eggar = []\n",
    "james = []\n",
    "\n",
    "for i, info_user in enumerate(all):\n",
    "    if i < indices:\n",
    "        eggar.append(info_user)\n",
    "    else:\n",
    "        james.append(info_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eggar.json', 'w') as f:\n",
    "    json.dump(eggar, f)\n",
    "\n",
    "with open('james.json', 'w') as f:\n",
    "    json.dump(james, f)\n",
    "\n",
    "with open(\"rein.json\", 'w') as f:\n",
    "    json.dump(rein, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://cdn.eternalai.org/ai-school-dataset/harrypotter.zip\n",
      "To: /Users/vuonggiahuy/Downloads/users_dataset/tmp/harrypotter.zip\n",
      "100%|██████████| 2.49M/2.49M [00:00<00:00, 16.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import gdown\n",
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "def download_and_unzip(urls):\n",
    "    \"\"\"\n",
    "    Downloads files from a list of URLs and zips them into a single zip file.\n",
    "    \n",
    "    Args:\n",
    "        urls (list): List of URLs of files to download.\n",
    "        zip_filename (str): Name of the zip file to create.\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the created zip file.\n",
    "    \"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()  # Create a temporary directory\n",
    "    # Download files\n",
    "    downloaded_files = []\n",
    "    for url in urls:\n",
    "        filename = os.path.basename(url)\n",
    "        file_path = os.path.join(temp_dir, filename)\n",
    "        gdown.download(url, file_path, quiet=False)    \n",
    "        downloaded_files.append(file_path)\n",
    "    # extract all zip from downloaded_files to tempdir\n",
    "    for file in downloaded_files:\n",
    "        with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "                \n",
    "    \n",
    "    return temp_dir\n",
    "\n",
    "# Example usage:\n",
    "urls = james[0][1][\"datasets\"]\n",
    "tmp_dir = download_and_unzip(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://cdn.generative.xyz/ai-school-dataset/Mozart.zip', 'https://cdn.generative.xyz/ai-school-dataset/Ravel.zip', 'https://cdn.generative.xyz/ai-school-dataset/Faure.zip']\n"
     ]
    }
   ],
   "source": [
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
